# AI Notebook Assistant (Fixed Version)

A full-stack AI assistant that uses Firebase Storage, FastAPI, and Next.js to create a RAG (Retrieval-Augmented Generation) system for your documents.

## ğŸ—ï¸ Architecture

```
ğŸ“‚ AI Notebook Assistant
â”œâ”€â”€ ğŸ”§ Backend (FastAPI + Firebase + Simple RAG)
â”‚   â”œâ”€â”€ Firebase Storage (documents) - Optional
â”‚   â”œâ”€â”€ Simple RAG Pipeline (keyword-based search)
â”‚   â””â”€â”€ Fallback to local files
â”œâ”€â”€ ğŸŒ Frontend (Next.js + Tailwind CSS)
â”‚   â””â”€â”€ Query Interface
â””â”€â”€ ğŸ“š Documents (Your ML Notes)
```

## ğŸš€ Quick Setup

### Option 1: Automated Setup

```bash
# Run the setup script
./setup.sh

# Start both servers
./start.sh
```

### Option 2: Manual Setup

#### Backend Setup

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install minimal dependencies
pip install -r requirements.txt

# Start the server
python3 main.py
```

#### Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

## ğŸ“‹ Features

âœ… **Firebase Storage Integration**: Automatically syncs documents from cloud storage  
âœ… **Fallback Support**: Works with local files if Firebase is not configured  
âœ… **Simple RAG**: Keyword-based search and context generation  
âœ… **Modern UI**: Clean Next.js interface with Tailwind CSS  
âœ… **Fast Setup**: Minimal dependencies for quick start

## ğŸ“š Supported Documents

- PDF files (`.pdf`) - requires PyPDF2
- Word documents (`.docx`) - requires python-docx
- Text files (`.txt`)
- Markdown files (`.md`)

## ğŸ”§ Configuration Options

### Option 1: Firebase Storage (Recommended for Production)

1. Create a Firebase project at https://console.firebase.google.com
2. Enable Firebase Storage
3. Create a service account and download credentials
4. Replace `backend/firebase_admin_config.json` with your credentials
5. Upload documents to `notebooks/` folder in Firebase Storage

### Option 2: Local Files (Quick Testing)

- The system automatically falls back to local files from `../NOTES/` folder
- No Firebase configuration needed
- Perfect for development and testing

## ğŸš€ Usage

1. **Start the system**: Run `./start.sh` or start backend/frontend manually
2. **Upload documents**: Either to Firebase Storage or place in local NOTES folder
3. **Visit http://localhost:3000**
4. **Ask questions** about your documents!

Example queries:

- "What is K-means clustering?"
- "Explain the difference between supervised and unsupervised learning"
- "How does hierarchical clustering work?"

## ğŸ› ï¸ Troubleshooting

### Common Issues

**Backend won't start:**

- Use `python3` instead of `python`
- Check virtual environment is activated: `source venv/bin/activate`
- Install dependencies: `pip install -r requirements.txt`

**No documents found:**

- Check if files are in Firebase Storage under `notebooks/` folder
- Or place files in local `../NOTES/` folder as fallback
- Supported formats: PDF, DOCX, TXT, MD

**Frontend issues:**

- Ensure backend is running on port 8000
- Check browser console for errors
- Run `npm install` to install dependencies

### File Structure Check

```bash
# Your project should look like this:
project/
â”œâ”€â”€ NOTES/                    # Your documents (fallback)
â”‚   â”œâ”€â”€ *.pdf
â”‚   â”œâ”€â”€ *.docx
â”‚   â””â”€â”€ *.txt
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ rag_pipeline_fixed.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ firebase_admin_config.json
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ components/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ setup.sh
â””â”€â”€ start.sh
```

## ğŸ“– API Endpoints

- `GET /`: Health check
- `GET /health`: Detailed system status
- `POST /query`: Submit a question (expects `{"question": "your question"}`)
- `GET /sources`: List available document sources

## ğŸ”„ Upgrade Path

To add advanced features later:

1. Install full LangChain: `pip install langchain langchain-community`
2. Add vector embeddings: `pip install sentence-transformers chromadb`
3. Add local LLM: `pip install transformers torch`
4. Switch to `rag_pipeline.py` in `main.py`

## ğŸ“Š RAG Approaches Comparison

Below is a comparison of different RAG (Retrieval-Augmented Generation) approaches implemented in this project:

![RAG Approaches Comparison](./assets/rag_comparison_table.png)

### Confidence Score Evolution

- **Initial TF-IDF**: Simple percentage based on keyword matches (sometimes as low as 27.3%)
- **Sentence Transformers**: Normalized cosine similarity between embeddings
- **Cross-Encoder**: Raw scores (could be negative, e.g., -102.4%) now normalized using sigmoid function:
  ```
  confidence = 100 * (1 / (1 + exp(-raw_score)))
  ```

## ğŸ“„ License

This project is for educational purposes. Modify as needed for your use case.